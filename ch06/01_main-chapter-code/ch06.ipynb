{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.4\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.1.0\n",
      "tensorflow version: 2.19.0\n",
      "pandas version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"numpy\",  # PyTorch & TensorFlow dependency\n",
    "    \"tiktoken\",  # Tokenizer\n",
    "    \"torch\",  # Deep learning library\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "    \"pandas\",  # Dataset loading\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(\n",
    "            f\"{data_file_path} already exists. Skipping download and extraction.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "\n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    \"\"\"\n",
    "    垃圾邮件数据集类，继承自PyTorch的Dataset类\n",
    "    用于加载和预处理垃圾邮件文本数据，实现数据的编码、填充等功能\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, csv_file, tokenizer, max_length=None, pad_token_id=50256\n",
    "    ):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        参数:\n",
    "            csv_file: 数据文件路径\n",
    "            tokenizer: 分词器对象\n",
    "            max_length: 序列最大长度，如果为None则使用数据集中最长序列的长度\n",
    "            pad_token_id: 填充token的ID，默认为50256\n",
    "        \"\"\"\n",
    "        # 读取CSV文件数据\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # 对文本进行预编码\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            # 如果未指定最大长度，则使用数据集中最长序列的长度\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # 如果序列长度超过max_length，则进行截断\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[: self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # 对所有序列进行填充，使其长度一致\n",
    "        self.encoded_texts = [\n",
    "            encoded_text\n",
    "            + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取数据集中的单个样本\n",
    "        参数:\n",
    "            index: 样本索引\n",
    "        返回:\n",
    "            编码后的文本张量和标签张量\n",
    "        \"\"\"\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集的样本数量\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        \"\"\"\n",
    "        计算数据集中最长序列的长度\n",
    "        返回:\n",
    "            最长序列的长度\n",
    "        \"\"\"\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # 注意：一个更pythonic的实现方式如下\n",
    "        # 这个方式在下一章中使用：\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\", max_length=None, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,  # Dropout rate\n",
    "    \"qkv_bias\": True,  # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text,\n",
    ")\n",
    "\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate_text_simple,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子为123，确保实验结果可重现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 定义分类任务的类别数量为2（二分类问题）\n",
    "num_classes = 2\n",
    "\n",
    "# 创建模型的输出层（全连接层）\n",
    "# - 输入特征维度：使用BASE_CONFIG中定义的嵌入维度\n",
    "# - 输出特征维度：等于类别数量\n",
    "# 这一层将把模型的嵌入表示转换为最终的分类logits\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "# 启用最后一个Transformer块中所有参数的梯度计算\n",
    "# 这对于微调模型的最后一层很重要，可以让模型适应新的任务\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 启用最终归一化层中所有参数的梯度计算\n",
    "# 最终归一化层对输出进行标准化处理，对模型性能有重要影响\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)  # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\n",
    "    \"Outputs dimensions:\", outputs.shape\n",
    ")  # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    计算模型在给定数据加载器上的准确率\n",
    "\n",
    "    参数:\n",
    "        data_loader: 数据加载器，包含输入批次和目标批次\n",
    "        model: 要评估的模型\n",
    "        device: 计算设备(CPU/GPU)\n",
    "        num_batches: 要评估的批次数量，如果为None则评估所有批次\n",
    "\n",
    "    返回:\n",
    "        float: 准确率（正确预测数 / 总样本数）\n",
    "    \"\"\"\n",
    "    # 将模型设置为评估模式\n",
    "    model.eval()\n",
    "    # 初始化计数器\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    # 确定要处理的批次数\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # 遍历数据加载器中的批次\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # 将数据移动到指定设备\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(\n",
    "                device\n",
    "            )\n",
    "\n",
    "            # 在不计算梯度的情况下进行前向传播\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[\n",
    "                    :, -1, :\n",
    "                ]  # 获取最后一个输出token的logits值\n",
    "\n",
    "            # 获取预测标签（选择logits中最大值的索引）\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # 更新统计数据\n",
    "            num_examples += predicted_labels.shape[0]  # 累加样本数\n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )  # 累加正确预测数\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 返回准确率\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "# else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "# print(f\"Running on {device} device.\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(\"Using 1 GPU!\")\n",
    "\n",
    "model.to(\n",
    "    device\n",
    ")  # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(\n",
    "    123\n",
    ")  # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with (\n",
    "    torch.no_grad()\n",
    "):  # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# 与第5章中的 `train_model_simple` 基本相同\n",
    "def train_classifier_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "):\n",
    "    \"\"\"\n",
    "    简单分类器训练函数\n",
    "    参数:\n",
    "        model: 待训练的模型\n",
    "        train_loader: 训练数据加载器\n",
    "        val_loader: 验证数据加载器\n",
    "        optimizer: 优化器\n",
    "        device: 计算设备(CPU/GPU)\n",
    "        num_epochs: 训练轮数\n",
    "        eval_freq: 评估频率(每多少步评估一次)\n",
    "        eval_iter: 评估时使用的批次数\n",
    "    \"\"\"\n",
    "    # 初始化列表用于跟踪损失和准确率\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1  # 初始化已处理样本数和全局步数\n",
    "\n",
    "    # 主训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 将模型设置为训练模式\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # 重置上一批次的梯度\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )  # 计算当前批次的损失\n",
    "            loss.backward()  # 计算损失梯度\n",
    "            optimizer.step()  # 使用梯度更新模型权重\n",
    "            examples_seen += input_batch.shape[0]  # 更新已处理的样本数量\n",
    "            global_step += 1\n",
    "\n",
    "            # 定期评估步骤\n",
    "            if global_step % eval_freq == 0:\n",
    "                # 在训练集和验证集上评估模型\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # 每个epoch结束后计算准确率\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    # 返回训练过程中记录的所有指标\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 6 (Step 000650): Train loss 0.129, Val loss 0.083\n",
      "Ep 6 (Step 000700): Train loss 0.020, Val loss 0.073\n",
      "Ep 6 (Step 000750): Train loss 0.046, Val loss 0.075\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 7 (Step 000800): Train loss 0.016, Val loss 0.087\n",
      "Ep 7 (Step 000850): Train loss 0.119, Val loss 0.062\n",
      "Ep 7 (Step 000900): Train loss 0.056, Val loss 0.121\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 8 (Step 000950): Train loss 0.186, Val loss 0.070\n",
      "Ep 8 (Step 001000): Train loss 0.010, Val loss 0.077\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 9 (Step 001050): Train loss 0.237, Val loss 0.085\n",
      "Ep 9 (Step 001100): Train loss 0.022, Val loss 0.091\n",
      "Ep 9 (Step 001150): Train loss 0.009, Val loss 0.072\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 10 (Step 001200): Train loss 0.007, Val loss 0.040\n",
      "Ep 10 (Step 001250): Train loss 0.014, Val loss 0.104\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 11 (Step 001300): Train loss 0.033, Val loss 0.094\n",
      "Ep 11 (Step 001350): Train loss 0.010, Val loss 0.058\n",
      "Ep 11 (Step 001400): Train loss 0.019, Val loss 0.129\n",
      "Training accuracy: 95.00% | Validation accuracy: 97.50%\n",
      "Ep 12 (Step 001450): Train loss 0.004, Val loss 0.092\n",
      "Ep 12 (Step 001500): Train loss 0.014, Val loss 0.159\n",
      "Ep 12 (Step 001550): Train loss 0.011, Val loss 0.053\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 13 (Step 001600): Train loss 0.109, Val loss 0.064\n",
      "Ep 13 (Step 001650): Train loss 0.023, Val loss 0.028\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 14 (Step 001700): Train loss 0.004, Val loss 0.033\n",
      "Ep 14 (Step 001750): Train loss 0.008, Val loss 0.079\n",
      "Ep 14 (Step 001800): Train loss 0.125, Val loss 0.083\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 15 (Step 001850): Train loss 0.097, Val loss 0.364\n",
      "Ep 15 (Step 001900): Train loss 0.054, Val loss 0.046\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 16 (Step 001950): Train loss 0.102, Val loss 0.092\n",
      "Ep 16 (Step 002000): Train loss 0.009, Val loss 0.113\n",
      "Ep 16 (Step 002050): Train loss 0.000, Val loss 0.089\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 17 (Step 002100): Train loss 0.005, Val loss 0.082\n",
      "Ep 17 (Step 002150): Train loss 0.002, Val loss 0.065\n",
      "Ep 17 (Step 002200): Train loss 0.003, Val loss 0.130\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 18 (Step 002250): Train loss 0.001, Val loss 0.075\n",
      "Ep 18 (Step 002300): Train loss 0.000, Val loss 0.066\n",
      "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
      "Ep 19 (Step 002350): Train loss 0.011, Val loss 0.117\n",
      "Ep 19 (Step 002400): Train loss 0.001, Val loss 0.054\n",
      "Ep 19 (Step 002450): Train loss 0.001, Val loss 0.135\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 20 (Step 002500): Train loss 0.000, Val loss 0.110\n",
      "Ep 20 (Step 002550): Train loss 0.014, Val loss 0.157\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 1.34 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = (\n",
    "    train_classifier_simple(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        eval_freq=50,\n",
    "        eval_iter=5,\n",
    "    )\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_values(\n",
    "    epochs_seen, examples_seen, train_values, val_values, label=\"loss\"\n",
    "):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(\n",
    "        examples_seen, train_values, alpha=0\n",
    "    )  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.81%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 96.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "    text, model, tokenizer, device, max_length=None, pad_token_id=50256\n",
    "):\n",
    "    \"\"\"\n",
    "    对输入文本进行分类，判断是否为垃圾信息\n",
    "\n",
    "    参数:\n",
    "    text (str): 待分类的输入文本\n",
    "    model: 用于分类的模型\n",
    "    tokenizer: 用于文本编码的分词器\n",
    "    device: 运行设备(CPU/GPU)\n",
    "    max_length (int): 最大序列长度\n",
    "    pad_token_id (int): 填充token的ID，默认为50256\n",
    "    \"\"\"\n",
    "    # 将模型设置为评估模式\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    # 将输入文本转换为token ID序列\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # 获取模型支持的最大上下文长度\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # 如果序列过长，进行截断处理\n",
    "    input_ids = input_ids[: min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert (\n",
    "        max_length <= supported_context_length\n",
    "    ), f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
    "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "\n",
    "    # 使用pad_token_id进行序列填充，确保所有序列长度一致\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    # 将序列转换为tensor，并添加batch维度\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(\n",
    "        0\n",
    "    )  # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    # 使用torch.no_grad()进行模型推理，提高效率并节省内存\n",
    "    with torch.no_grad():\n",
    "        # 获取最后一个token的logits输出\n",
    "        logits = model(input_tensor)[\n",
    "            :, -1, :\n",
    "        ]  # Logits of the last output token\n",
    "    # 获取预测标签\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    # 返回分类结果：如果预测标签为1则为垃圾信息，否则不是垃圾信息\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    classify_review(\n",
    "        text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    classify_review(\n",
    "        text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a5a7a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = \"You win a big prize, click link see more\"\n",
    "\n",
    "print(\n",
    "    classify_review(\n",
    "        text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "fileId": "fd6c3d49-d850-420e-a7c5-34f7def79e1c",
  "filePath": "/gaobo.gl/LLMs-from-scratch/ch06/01_main-chapter-code/ch06.ipynb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python392jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
